{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a demo text for nlp using nltk. full form of nltk is natural language toolkit\n"
     ]
    }
   ],
   "source": [
    "\"\"\"convert text to lower case:\n",
    "\n",
    "It is necessary to convert the text to lower case as it is case sensitive.\"\"\"\n",
    "\n",
    "\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "lower_text = text.lower()\n",
    "print (lower_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'Demo', 'Text', 'for', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'of', 'NLTK', 'is', 'Natural', 'Language', 'Toolkit']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"word tokenize\n",
    "\n",
    "Tokenize sentences to get the tokens of the text i.e breaking the sentences into words.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "print (word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a Demo Text for NLP using NLTK.', 'Full form of NLTK is Natural Language Toolkit']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sent tokenize\n",
    "\n",
    "Tokenize sentences if the there are more than 1 sentence i.e breaking the sentences \n",
    "to list of sentence.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "sent_token = nltk.sent_tokenize(text)\n",
    "print (sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'Demo', 'Text', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'NLTK', 'Natural', 'Language', 'Toolkit']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words('english')\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "removing_stopwords = [word for word in word_tokens if word not in stopword]\n",
    "print (removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'Demo', 'Text', 'for', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'of', 'NLTK', 'is', 'Natural', 'Language', 'Toolkit']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#is based on The Porter Stemming Algorithm\n",
    "stopword = stopwords.words('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "print (lemmatized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'demo', 'text', 'for', 'nlp', 'use', 'nltk', '.', 'full', 'form', 'of', 'nltk', 'is', 'natur', 'languag', 'toolkit']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "#is based on The Porter Stemming Algorithm\n",
    "stopword = stopwords.words('english')\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "print (stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 2), ('nltk', 2), ('this', 1), ('a', 1), ('demo', 1)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get word frequency\n",
    "\n",
    "counting the word occurrence using FreqDist library\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word = nltk.word_tokenize(text.lower())\n",
    "freq = FreqDist(word)\n",
    "print (freq.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 2), ('nltk', 2), ('this', 1), ('a', 1), ('demo', 1)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "text = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word = nltk.word_tokenize(text.lower())\n",
    "freq = FreqDist(word)\n",
    "print (freq.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('Demo', 'NNP'), ('Text', 'NNP'), ('for', 'IN'), ('NLP', 'NNP'), ('using', 'VBG'), ('NLTK', 'NNP'), ('.', '.'), ('Full', 'NNP'), ('form', 'NN'), ('of', 'IN'), ('NLTK', 'NNP'), ('is', 'VBZ'), ('Natural', 'JJ'), ('Language', 'NNP'), ('Toolkit', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"pos(Part of Speech)tags\n",
    "\n",
    "POS tag helps us to know the tags of each word like whether a word is noun, adjective etc.\"\"\"\n",
    "\n",
    "import nltk\n",
    "\n",
    "word = nltk.word_tokenize(text)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "print (pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Demo Text', 'NLP', 'NLTK', 'NLTK', 'Natural Language Toolkit']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"NER\n",
    "\n",
    "NER(Named Entity Recognition) is the process of getting the entity names\"\"\"\n",
    "\n",
    "import nltk\n",
    "\n",
    "word = nltk.word_tokenize(text)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in chunk if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
